{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-29T05:33:12.906566Z","iopub.status.busy":"2025-03-29T05:33:12.906170Z","iopub.status.idle":"2025-03-29T05:33:12.909968Z","shell.execute_reply":"2025-03-29T05:33:12.909198Z","shell.execute_reply.started":"2025-03-29T05:33:12.906535Z"},"trusted":true},"outputs":[],"source":["# # Cài đặt các gói cần thiết\n","# !pip install pytorch-lightning\n","# !pip install torchmetrics\n","# !pip install transformers\n","# !pip install datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-29T05:33:12.919370Z","iopub.status.busy":"2025-03-29T05:33:12.919096Z","iopub.status.idle":"2025-03-29T05:33:34.077337Z","shell.execute_reply":"2025-03-29T05:33:34.076652Z","shell.execute_reply.started":"2025-03-29T05:33:12.919350Z"},"trusted":true},"outputs":[],"source":["# Import các thư viện cần thiết\n","import os\n","import zipfile\n","from pathlib import Path\n","from typing import Any, Dict, List, Optional, Tuple, Union\n","from urllib.request import urlretrieve\n","\n","import pandas as pd\n","from tqdm import tqdm\n","\n","import pytorch_lightning as pl\n","import torch\n","import torch.nn.functional as F\n","import torchmetrics\n","from datasets import load_dataset\n","from pytorch_lightning import loggers as pl_loggers\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","from torch.utils.data import DataLoader\n","from transformers import (AutoModelForSequenceClassification, AutoTokenizer,\n","                          DataCollatorWithPadding)\n","\n","# Đặt seed để đảm bảo tính tái tạo\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-29T05:33:34.079057Z","iopub.status.busy":"2025-03-29T05:33:34.078389Z","iopub.status.idle":"2025-03-29T05:33:34.088155Z","shell.execute_reply":"2025-03-29T05:33:34.087331Z","shell.execute_reply.started":"2025-03-29T05:33:34.079022Z"},"trusted":true},"outputs":[],"source":["class TqdmUpTo(tqdm):\n","    \"\"\"From https://github.com/tqdm/tqdm/blob/master/examples/tqdm_wget.py\"\"\"\n","\n","    def update_to(self, blocks=1, bsize=1, tsize=None):\n","        \"\"\"\n","        Parameters\n","        ----------\n","        blocks: int, optional\n","            Number of blocks transferred so far [default: 1].\n","        bsize: int, optional\n","            Size of each block (in tqdm units) [default: 1].\n","        tsize: int, optional\n","            Total size (in tqdm units). If [default: None] remains unchanged.\n","        \"\"\"\n","        if tsize is not None:\n","            self.total = tsize  # pylint: disable=attribute-defined-outside-init\n","        self.update(blocks * bsize - self.n)  # will also set self.n = b * bsize\n","\n","\n","def download_url(url, filename, directory='.'):\n","    \"\"\"Download a file from url to filename, with a progress bar.\"\"\"\n","    if not os.path.exists(directory):\n","        os.makedirs(directory)\n","    path = os.path.join(directory, filename)\n","\n","    with TqdmUpTo(unit=\"B\", unit_scale=True, unit_divisor=1024, miniters=1) as t:\n","        urlretrieve(url, path, reporthook=t.update_to, data=None)  # nosec\n","    return path\n","\n","def _load_data_from(data_dir: Union[str, Path]):\n","    \"\"\"Load dữ liệu cảm xúc từ tệp văn bản\"\"\"\n","    fnames = ['sentiments.txt', 'sents.txt', 'topics.txt']\n","    sentiments = []\n","    sents = []\n","    topics = []\n","    for name in fnames:\n","        with open(f\"{data_dir}/{name}\", 'r') as f:\n","            if name == \"sentiments.txt\":\n","                sentiments = [int(line.strip()) for line in f.readlines()]\n","            elif name == \"sents.txt\":\n","                sents = [line.strip() for line in f.readlines()]        \n","            else:\n","                topics = [int(line.strip()) for line in f.readlines()]\n","    return sents, sentiments, topics\n","\n","def _save_to_csv(file_path: Union[str, Path], data):\n","    \"\"\"Chuyển đổi dữ liệu sang định dạng CSV\"\"\"\n","    sents, sentiments, topics = data\n","    df = pd.DataFrame({\n","        \"sents\": sents,\n","        \"labels\": sentiments,\n","        \"topics\": topics\n","    })\n","    df.to_csv(file_path, index=False)\n","    return file_path"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-29T05:33:34.090109Z","iopub.status.busy":"2025-03-29T05:33:34.089867Z","iopub.status.idle":"2025-03-29T05:33:34.121396Z","shell.execute_reply":"2025-03-29T05:33:34.120795Z","shell.execute_reply.started":"2025-03-29T05:33:34.090090Z"},"trusted":true},"outputs":[],"source":["class UIT_VSFC(pl.LightningDataModule):\n","    \"\"\"\n","    UIT-VSFC: Vietnamese Students' Feedback Corpus for sentiment analysis\n","    \"\"\"\n","    def __init__(self, tokenizer, opts: Dict[str, Any]):\n","        super().__init__()\n","        self.tokenizer = tokenizer\n","        self.batch_size = opts['batch_size']\n","        self.num_workers = opts['num_workers']\n","        self.on_gpu = opts['on_gpu']\n","        self.data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","        self.dataset = None\n","        self.mapping = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n","        self.inverse_mapping = {v: k for k, v in self.mapping.items()}\n","        \n","        # Tải dataset luôn khi khởi tạo để tránh lỗi setup\n","        self.raw_datasets = load_dataset(\"uitnlp/vietnamese_students_feedback\")\n","        \n","    def prepare_data(self):\n","        # Phương thức này chỉ gọi một lần và không cần trả về gì\n","        pass\n","\n","    def setup(self, stage=None):\n","        # Kiểm tra cấu trúc dữ liệu\n","        sample = self.raw_datasets['train'][0]\n","        print(\"Cấu trúc dữ liệu mẫu:\", sample)\n","        \n","        # Hàm tokenize đầu vào\n","        def tokenize_function(examples):\n","            # Thêm truncation=True để đảm bảo độ dài phù hợp\n","            return self.tokenizer(examples['sentence'], truncation=True, max_length=256)\n","        \n","        if self.dataset is None:\n","            # Tạo dataset nếu chưa được tạo\n","            splits = {\n","                'train': self.raw_datasets['train'],\n","                'dev': self.raw_datasets['validation'],\n","                'test': self.raw_datasets['test']\n","            }\n","            \n","            # Áp dụng tokenize và định dạng\n","            self.dataset = {}\n","            for split_name, split_data in splits.items():\n","                print(f\"Xử lý split: {split_name}\")\n","                # Áp dụng tokenizer\n","                try:\n","                    # Áp dụng tokenizer\n","                    tokenized_data = split_data.map(\n","                        tokenize_function,\n","                        batched=True,\n","                        remove_columns=['sentence', 'topic']  # Xóa cột không cần thiết\n","                    )\n","                    \n","                    # In thông tin cột để debug\n","                    print(f\"Các cột sau khi tokenize: {tokenized_data.column_names}\")\n","                    \n","                    # Lưu lại dữ liệu tokenized trước khi chuyển đổi định dạng\n","                    self.dataset[split_name] = tokenized_data\n","                    \n","                    # Tạo dataset với các trường cần thiết\n","                    formatted_data = tokenized_data.with_format(\n","                        type='torch',\n","                        columns=['input_ids', 'attention_mask', 'sentiment'],\n","                        output_all_columns=False  # Chỉ giữ lại các cột đã chỉ định\n","                    )\n","                    \n","                    # Kiểm tra dữ liệu đã được định dạng\n","                    if formatted_data is not None:\n","                        # Đổi tên cột\n","                        formatted_data = formatted_data.rename_column('sentiment', 'labels')\n","                        self.dataset[split_name] = formatted_data\n","                    else:\n","                        print(f\"Lỗi: Không thể định dạng dữ liệu cho split {split_name}\")\n","                \n","                except Exception as e:\n","                    print(f\"Lỗi khi xử lý split {split_name}: {str(e)}\")\n","                    # Sử dụng cách tiếp cận thủ công nếu cách trên không hoạt động\n","                    try:\n","                        print(\"Thử phương pháp thay thế...\")\n","                        # Tiếp cận thủ công để tạo tensor\n","                        tokenized_data = split_data.map(\n","                            tokenize_function,\n","                            batched=True\n","                        )\n","                        \n","                        # Chuyển đổi thành dict of lists\n","                        data_dict = {\n","                            'input_ids': tokenized_data['input_ids'],\n","                            'attention_mask': tokenized_data['attention_mask'],\n","                            'labels': tokenized_data['sentiment']  # Đổi tên ngay tại đây\n","                        }\n","                        \n","                        # Tạo datasets từ dict\n","                        from datasets import Dataset\n","                        self.dataset[split_name] = Dataset.from_dict(data_dict).with_format(\"torch\")\n","                    except Exception as e2:\n","                        print(f\"Cả hai phương pháp đều thất bại cho split {split_name}: {str(e2)}\")\n","                        continue\n","    \n","    def train_dataloader(self):\n","        # Đảm bảo setup đã được gọi\n","        if self.dataset is None:\n","            self.setup()\n","            \n","        if 'train' not in self.dataset or self.dataset['train'] is None:\n","            raise ValueError(\"Train dataset không khả dụng\")\n","            \n","        return DataLoader(\n","            self.dataset['train'],\n","            shuffle=True,\n","            batch_size=self.batch_size,\n","            num_workers=self.num_workers,\n","            pin_memory=self.on_gpu,\n","            collate_fn=self.data_collator\n","        )\n","    \n","    def val_dataloader(self):\n","        # Đảm bảo setup đã được gọi\n","        if self.dataset is None:\n","            self.setup()\n","            \n","        if 'dev' not in self.dataset or self.dataset['dev'] is None:\n","            raise ValueError(\"Validation dataset không khả dụng\")\n","            \n","        return DataLoader(\n","            self.dataset['dev'],\n","            shuffle=False,\n","            batch_size=self.batch_size,\n","            num_workers=self.num_workers,\n","            pin_memory=self.on_gpu,\n","            collate_fn=self.data_collator\n","        )\n","    \n","    def test_dataloader(self):\n","        # Đảm bảo setup đã được gọi\n","        if self.dataset is None:\n","            self.setup()\n","            \n","        if 'test' not in self.dataset or self.dataset['test'] is None:\n","            raise ValueError(\"Test dataset không khả dụng\")\n","            \n","        return DataLoader(\n","            self.dataset['test'],\n","            shuffle=False,\n","            batch_size=self.batch_size,\n","            num_workers=self.num_workers,\n","            pin_memory=self.on_gpu,\n","            collate_fn=self.data_collator\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-29T05:33:34.122650Z","iopub.status.busy":"2025-03-29T05:33:34.122413Z","iopub.status.idle":"2025-03-29T05:33:34.143360Z","shell.execute_reply":"2025-03-29T05:33:34.142779Z","shell.execute_reply.started":"2025-03-29T05:33:34.122630Z"},"trusted":true},"outputs":[],"source":["class PhoBERT(pl.LightningModule):\n","    def __init__(self, lr, weight_decay):\n","        super().__init__()\n","        self.model = AutoModelForSequenceClassification.from_pretrained(\"vinai/phobert-base\", num_labels=3)\n","        self.lr = lr\n","        self.weight_decay = weight_decay\n","\n","        # Định nghĩa các metrics\n","        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=3)\n","        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=3)\n","        self.val_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=3)\n","        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=3)\n","        self.test_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=3)\n","    \n","    def configure_optimizers(self):\n","        return torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n","    \n","    def training_step(self, batch, batch_idx):\n","        outputs = self.model(**batch)\n","        loss, logits = outputs.loss, outputs.logits\n","        sentiments = batch['labels']\n","        scores = F.softmax(logits, dim=-1)\n","        self.train_acc(scores, sentiments)\n","        self.log('train_acc', self.train_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n","        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        outputs = self.model(**batch)\n","        loss, logits = outputs.loss, outputs.logits\n","        sentiments = batch['labels']\n","        scores = F.softmax(logits, dim=-1)\n","        self.val_acc(scores, sentiments)\n","        self.val_f1(scores, sentiments)\n","        \n","        # Cải thiện cách log metrics\n","        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n","        self.log('val_acc', self.val_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n","        self.log('val_f1', self.val_f1, on_step=False, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n","\n","    def test_step(self, batch, batch_idx):\n","        outputs = self.model(**batch)\n","        logits = outputs.logits\n","        sentiments = batch['labels']\n","        scores = F.softmax(logits, dim=-1)\n","        self.test_acc(scores, sentiments)\n","        self.test_f1(scores, sentiments)\n","        \n","        # Cải thiện cách log metrics\n","        self.log('test_acc', self.test_acc, on_step=False, on_epoch=True, logger=True)\n","        self.log('test_f1', self.test_f1, on_step=False, on_epoch=True, logger=True)\n","\n","    # Thêm phương thức on_validation_epoch_end để đảm bảo metrics được tính toán đầy đủ\n","    def on_validation_epoch_end(self):\n","        # Log lại metrics một lần nữa ở cuối epoch\n","        self.log('val_acc_epoch', self.val_acc.compute(), prog_bar=True, logger=True)\n","        self.log('val_f1_epoch', self.val_f1.compute(), prog_bar=True, logger=True)\n","        \n","        # In thông tin để debug\n","        print(f\"Epoch end val_f1: {self.val_f1.compute():.4f}, val_acc: {self.val_acc.compute():.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-29T05:33:34.144403Z","iopub.status.busy":"2025-03-29T05:33:34.144178Z","iopub.status.idle":"2025-03-29T05:33:34.160600Z","shell.execute_reply":"2025-03-29T05:33:34.159832Z","shell.execute_reply.started":"2025-03-29T05:33:34.144385Z"},"trusted":true},"outputs":[],"source":["    def validation_step(self, batch, batch_idx):\n","        outputs = self.model(**batch)\n","        loss, logits = outputs.loss, outputs.logits\n","        sentiments = batch['labels']\n","        scores = F.softmax(logits, dim=-1)\n","        self.val_acc(scores, sentiments)\n","        self.val_f1(scores, sentiments)\n","        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n","        self.log('val_acc', self.val_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n","        self.log('val_f1', self.val_f1, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n","\n","    def test_step(self, batch, batch_idx):\n","        outputs = self.model(**batch)\n","        logits = outputs.logits\n","        sentiments = batch['labels']\n","        scores = F.softmax(logits, dim=-1)\n","        self.test_acc(scores, sentiments)\n","        self.test_f1(scores, sentiments)\n","        self.log('test_acc', self.test_acc, on_step=False, on_epoch=True, logger=True)\n","        self.log('test_f1', self.test_f1, on_step=False, on_epoch=True, logger=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-29T05:33:34.161728Z","iopub.status.busy":"2025-03-29T05:33:34.161451Z","iopub.status.idle":"2025-03-29T05:46:11.116959Z","shell.execute_reply":"2025-03-29T05:46:11.116191Z","shell.execute_reply.started":"2025-03-29T05:33:34.161702Z"},"trusted":true},"outputs":[],"source":["# Khởi tạo tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n","\n","# Tùy chọn cho datamodule\n","options = {\n","    \"on_gpu\": torch.cuda.is_available(),\n","    \"batch_size\": 16,\n","    \"num_workers\": 2\n","}\n","\n","# Khởi tạo datamodule\n","datamodule = UIT_VSFC(tokenizer, options)\n","\n","# Các siêu tham số\n","lr = 2e-5\n","weight_decay = 0.01\n","\n","# Khởi tạo mô hình\n","model = PhoBERT(lr, weight_decay)\n","\n","# Thiết lập callback lưu checkpoint\n","checkpoint_callback = ModelCheckpoint(\n","    monitor='val_f1',\n","    dirpath='checkpoints',\n","    filename='phobert-sentiment-{epoch:02d}-{val_f1:.4f}',\n","    save_top_k=1,\n","    mode='max',\n",")\n","\n","# Khởi tạo trainer\n","trainer = pl.Trainer(\n","    max_epochs=10,\n","    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n","    devices=1,\n","    callbacks=[checkpoint_callback],\n","    deterministic=True,\n",")\n","\n","# Kiểm tra dataloader trước khi huấn luyện (tùy chọn)\n","datamodule.setup()\n","batch = next(iter(datamodule.train_dataloader()))\n","print(\"Batch keys:\", batch.keys())\n","print(\"Input ids shape:\", batch['input_ids'].shape)\n","print(\"Labels shape:\", batch['labels'].shape if 'labels' in batch else \"Labels not found\")\n","\n","# Huấn luyện mô hình\n","trainer.fit(model, datamodule)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-29T05:46:11.118308Z","iopub.status.busy":"2025-03-29T05:46:11.117962Z","iopub.status.idle":"2025-03-29T05:46:18.853929Z","shell.execute_reply":"2025-03-29T05:46:18.852916Z","shell.execute_reply.started":"2025-03-29T05:46:11.118273Z"},"trusted":true},"outputs":[],"source":["# Kiểm tra mô hình sử dụng checkpoint tốt nhất\n","test_results = trainer.test(ckpt_path=checkpoint_callback.best_model_path, datamodule=datamodule)\n","print(f\"Kết quả kiểm tra: {test_results}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-29T05:46:18.856219Z","iopub.status.busy":"2025-03-29T05:46:18.855977Z","iopub.status.idle":"2025-03-29T05:46:19.141522Z","shell.execute_reply":"2025-03-29T05:46:19.140632Z","shell.execute_reply.started":"2025-03-29T05:46:18.856196Z"},"trusted":true},"outputs":[],"source":["# Hiển thị kết quả và so sánh với baseline\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Kết quả từ mô hình của chúng ta\n","our_results = {\n","    'Accuracy': test_results[0]['test_acc'],\n","    'F1 Score': test_results[0]['test_f1']\n","}\n","\n","# Kết quả từ bài báo\n","paper_results = {\n","    'Accuracy': 0.879,\n","    'F1 Score': 0.879\n","}\n","\n","# Tạo biểu đồ cột để so sánh kết quả\n","models = ['PhoBERT (Cài đặt của chúng ta)', 'MaxEnt (Bài báo gốc)']\n","metrics = ['Accuracy', 'F1 Score']\n","\n","x = np.arange(len(metrics))\n","width = 0.35\n","\n","fig, ax = plt.subplots(figsize=(10, 6))\n","rects1 = ax.bar(x - width/2, [our_results[m] for m in metrics], width, label=models[0])\n","rects2 = ax.bar(x + width/2, [paper_results[m] for m in metrics], width, label=models[1])\n","\n","ax.set_ylabel('Điểm số')\n","ax.set_title('So sánh hiệu suất trên tập dữ liệu UIT-VSFC')\n","ax.set_xticks(x)\n","ax.set_xticklabels(metrics)\n","ax.legend()\n","\n","ax.bar_label(rects1, padding=3, fmt='%.3f')\n","ax.bar_label(rects2, padding=3, fmt='%.3f')\n","fig.tight_layout()\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-29T05:46:19.142960Z","iopub.status.busy":"2025-03-29T05:46:19.142619Z","iopub.status.idle":"2025-03-29T05:46:19.149516Z","shell.execute_reply":"2025-03-29T05:46:19.148664Z","shell.execute_reply.started":"2025-03-29T05:46:19.142926Z"},"trusted":true},"outputs":[],"source":["print(\"Thảo luận:\")\n","print(\"Mô hình PhoBERT của chúng ta đạt độ chính xác {:.2f}% và điểm F1 {:.2f}%, \".format(\n","    our_results['Accuracy']*100, our_results['F1 Score']*100))\n","print(\"vượt trội hơn baseline MaxEnt từ bài báo gốc {:.2f}% \".format(\n","    (our_results['Accuracy'] - paper_results['Accuracy'])*100))\n","print(\"mà không cần điều chỉnh siêu tham số nhiều.\")\n","print(\"\\nCác cải tiến tiềm năng:\")\n","print(\"1. Lên lịch cho tốc độ học (learning rate scheduling)\")\n","print(\"2. Điều chỉnh siêu tham số rộng rãi hơn bằng cách sử dụng Wandb sweeps\")\n","print(\"3. Thử nghiệm các mô hình pre-trained khác (XLM-RoBERTa, BERTweet, v.v.)\")\n","print(\"4. Tăng cường dữ liệu cho các lớp không cân bằng\")\n","print(\"5. Phương pháp tổng hợp kết hợp nhiều mô hình\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-29T06:07:45.088782Z","iopub.status.busy":"2025-03-29T06:07:45.088461Z","iopub.status.idle":"2025-03-29T06:07:45.095213Z","shell.execute_reply":"2025-03-29T06:07:45.094391Z","shell.execute_reply.started":"2025-03-29T06:07:45.088759Z"},"trusted":true},"outputs":[],"source":["# In ra đường dẫn của checkpoint tốt nhất\n","print(f\"Đường dẫn đến checkpoint tốt nhất: {checkpoint_callback.best_model_path}\")\n","\n","# Nếu bạn muốn sao chép checkpoint tốt nhất vào một thư mục khác\n","import os\n","import shutil\n","\n","best_ckpt = checkpoint_callback.best_model_path\n","output_dir = '/kaggle/working/checkpoints'\n","os.makedirs(output_dir, exist_ok=True)\n","output_file = os.path.join(output_dir, os.path.basename(best_ckpt))\n","print(f\"Đã sao chép checkpoint tốt nhất vào: {output_file}\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":6995399,"sourceId":11203773,"sourceType":"datasetVersion"}],"dockerImageVersionId":30918,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
